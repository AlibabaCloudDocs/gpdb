# 规格及实例选型 {#concept_mp2_hbr_52b .concept}

## 计算组规格定义 {#section_j3w_5fj_rhb .section}

分析型数据库PostgreSQL版 为MPP全并行执行的集群架构实例，其集群实例由多个[计算组规格](ZH-CN_TP_16837_V3.dita#concept_emc_dfr_52b)组成。集群可水平扩展[计算组数量](ZH-CN_TP_16837_V3.dita#concept_emc_dfr_52b)，而保证数据容量增加下，查询响应时延不变。

![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/16835/156569672951402_zh-CN.png)

AnalyticDB for PostgreSQL提供两种计算组类型

-   高性能计算组

    采用SSD存储，规格简称为*n***x***m***C****SSD**，*m*代表该计算组含有的数据分区数（Segment），*n*代表单数据分区的CPU核数，规格全称以 **gpdb.group.segsdx**开始。特点是可以提供更好的 I/O能力，带来更高的分析性能。

-   高容量计算组

    采用HDD存储，规格简称为*n***x***m***C****HDD**，*m*代表该计算组含有的数据分区数（Segment），*n*代表单数据分区的CPU核数，规格全称以**gpdb.group.seghdx**开始。特点是可以提供更大、更实惠的空间，满足更高的存储需求。


数据默认采用双副本存储，保证高可靠，发生存储硬件异常时，自动切换并修复。

高性能计算组的规格信息如下表所示。

|【高性能】计算组规格简称|【高性能】计算组规格全称|CPU|内存|总存储（双副本） / 用户数据空间|规格说明|
|:-----------|:-----------|:--|:-|:----------------|:---|
|1x2C SSD|gpdb.group.segsdx2|2 Cores|16 GB|320 GB/160 GB SSD|2个数据分区（segment），每个分区1CPU核|
|4x4C SSD|gpdb.group.segsd4cx4|16 Cores|128 GB|2.56 TB/1.28 TB SSD|4个数据分区（segment），每个分区4CPU核|
|1x16C SSD|gpdb.group.segsdx16|16 Cores|128 GB|2.56 TB/1.28 TB SSD|16个数据分区（segment），每个分区1CPU核|

**说明：** **4x4C SSD 和 1x16C SSD 计算组的选择：** 4x4C 规格对多种场景有较好的适配性，为主要推荐的计算组规格。1x16C 计算组单数据分区分配 1 个计算核，只适合低并发执行场景。建议简单查询（3表以内关联）5并发以内，可以考虑采用 1x16C 计算组。

高容量计算组的规格信息如下表所示：

|【高容量】计算组规格简称|【高容量】计算组规格全称|CPU|内存|总存储（双副本） / 用户数据空间|规格说明|
|:-----------|:-----------|:--|:-|:----------------|:---|
|2x2C HDD|gpdb.group.seghdx4|4 Cores|32 GB|4 TB/2 TB HDD|2个数据分区（segment），每个分区2CPU核。|
|4x4C HDD|gpdb.group.seghdx36|16 Cores|128 GB|16 TB/8 TB HDD|4个数据分区（segment），每个分区4CPU核。|

关于产品价格，请参考[产品定价](../../../../cn.zh-CN/产品定价/产品定价.md#)。

## 实例选型指导 {#section_xsx_3gj_rhb .section}

在云数据库AnalyticDB for PostgreSQL中创建或升级实例规格时，需要选择实例的**计算组规格**和**计算组数量**。 同时，AnalyticDB for PostgreSQL 支持基于 OSS的外部表扩展，并可通过gzip实现外部存储上的数据压缩，将不需要参与实时计算的数据可以存放到外部存储以进一步节省存储成本

**说明：** 关于计算组规格和计算组数量的定义，请参考[名词解释](cn.zh-CN/产品简介/名词解释.md#)。

**计算组类型选择**

对于性能优先类场景，建议以SSD高性能规格计算组构建分析数据仓库实例；对于以数据存储类优先的场景，可以考虑 HDD的高容量类型计算组。

**计算组数量选择**

AnalyticDB for PostgreSQL 采用 MPP 全并行架构，数据处理能力随计算组数量增加而线性增长，保证数据量增加而响应RT时间不变。可以参照原始数据量及应用场景，选择适合的计算组数量。

-   有较多数据更新操作或有实时写入的业务场景 （INSERT/UPDATE/DELETE ），建议采用行存储。

    对于1 TB 原始数据，入库后采用行存储，大小一般还是在 1 TB 左右，考虑到索引，日志，以及在计算过程中会产生临时文件等，建议按 2 TB 的用户数据空间来规划集群实例的计算组数量。若对查询性能要求较高，可以增加计算组数量，从而增加相应的CPU，内存等资源，提升查询性能。

-   批处理ETL场景，其数据一般较少被更新（UPDATE/DELETE），数据为批量入库，同时查询以少量列的全表数据聚合关联为主，建议采用列存储。

    列存储具备较高的数据压缩率，可以达到 2-5倍的压缩比，即对于1 TB原始数据，入库后若采用了列存储压缩设置，数据在0.5 TB以内，那么可以按 1 TB 的用户数据存储空间来规划集群实例的计算组数量。


**实例选型示例：**

如果有 5 TB 的原始数据，针对高性能分析场景，并有100并发以上的查询，建议采用8个4x4C SSD计算组规格，总计11.24 TB用户数据存储空间。

**说明：** [产品定价](https://www.aliyun.com/price/product#/gpdb/detail)中已经提供了一些常用计算组集群规格组合速查表。对于超过控制台自助创建页面的计算组数量，您可以通过提交工单或联系销售代表申请创建。

