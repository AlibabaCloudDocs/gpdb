# 规格及实例选型指导 {#concept_mp2_hbr_52b .concept}

## 计算组规格定义 {#section_j3w_5fj_rhb .section}

分析型数据库PostgreSQL版 为MPP全并行执行的集群架构实例，其单计算节点定位为**计算组**，有如下两种类型规格：

-   高性能规格计算组

    规格简称为*n***x***m***C****SSD**，*n*代表单分区（segment）分配的CPU核数，*m*代表该计算组的总分区数，规格全称以 **gpdb.group.segsdx**开始。特点是可以提供更好的 I/O能力，带来更高的分析性能。

-   高容量规格计算组

    规格简称为*n***x***m***C****HDD**，*n*代表单分区（segment）分配的CPU核数，*m*代表该计算组的总分区数，规格全称以**gpdb.group.seghdx**开始。特点是可以提供更大、更实惠的空间，满足更高的存储需求。


数据默认采用双副本存储，保证高可靠，发生存储硬件异常时，自动切换并修复。

高性能的规格信息如下表所示。

|【高性能】计算组规格简称|【高性能】计算组规格全称|CPU|内存|总存储（双副本） / 用户数据空间|规格说明|
|:-----------|:-----------|:--|:-|:----------------|:---|
|1x2C SSD|gpdb.group.segsdx2|2 Cores|16 GB|320 GB/160 GB SSD|2个数据分区（segment），每个分区1CPU核。|
|1x16C SSD|gpdb.group.segsdx16|16 Cores|128 GB|2.56 TB/1.28 TB SSD|16个数据分区（segment），每个分区1CPU核。|
|4x4C SSD|gpdb.group.segsd4cx4|16 Cores|128 GB|2.56 TB/1.28 TB SSD|4个数据分区（segment），每个分区4CPU核。|

**说明：** **4x4C SSD 和 1x16C SSD 计算组的选择：** 4x4C 规格对多种场景有较好的适配性，为主要推荐的计算组规格。1x16C 计算组单数据分区分配1个计算核，只适合低并发执行场景。建议简单查询（3表以内关联）5并发以内，可以考虑采用 1x16C 计算组。

高容量的规格信息如下表所示：

|【高容量】计算组规格简称|【高容量】计算组规格全称|CPU|内存|总存储（双副本） / 用户数据空间|规格说明|
|:-----------|:-----------|:--|:-|:----------------|:---|
|2x2 HDD|gpdb.group.seghdx4|4 Cores|32 GB|4 TB/2 TB HDD|2个数据分区（segment），每个分区2CPU核。|
|2x18 HDD|gpdb.group.seghdx36|36 Cores|288 GB|36 TB/18 TB HDD|18个数据分区（segment），每个分区2CPU核。|

关于产品价格，请参考[产品定价](../../../../cn.zh-CN/产品定价/产品定价.md#)。

## 实例选型 {#section_xsx_3gj_rhb .section}

在云数据库AnalyticDB for PostgreSQL中创建实例和升级实例规格时，需要选择单节点的**计算组规格**和集群的**计算组数量**。 同时，AnalyticDB for PostgreSQL支持基于 OSS的外部表扩展，并可通过gzip实现外部存储上的数据压缩，将不需要参与实时计算的数据可以存放到外部存储以进一步节省存储成本

**说明：** 关于计算组规格和计算组数量的定义，请参考[名词解释](cn.zh-CN/产品简介/名词解释.md#)。

**计算组类型选择**

对于性能优先类场景，建议以SSD高性能规格构建分析数据仓库实例；对于以数据存储类优先的场景，可以考虑 HDD高容量规格。

**计算组数量选择**

AnalyticDB for PostgreSQL 采用 MPP 全并行架构，数据处理能力随计算组数量增加而线性增长，保证数据量增加而响应RT时间不变。可以参照原始数据量及应用场景，选择适合的计算组数量。

-   基于主键的点查询场景，或者有较多数据更新操作或有实时写入的业务 （INSERT/UPDATE/DELETE ），建议采用行存储。

    对于1 TB原始数据，写入数据库后大小一般还是在 1 TB 左右，考虑到索引，日志，以及在计算过程中会产生临时文件等，建议按 2 TB 的用户数据空间来规划集群实例的计算组数量。如果对查询性能要求较高，可以增加计算组数量，从而增加对应的CPU，内存等资源，提升查询性能。

-   批处理ETL场景，其数据一般较少被更新（UPDATE/DELETE），同时查询以全表数据聚合关联为主，建议采用列存储。

    同时列存存储具备较高的数据压缩率，当压缩级别设为 1 时，可以达到 2-5倍的压缩比，即对于1 TB原始数据，入库后若采用了列存储压缩设置，数据在0.5 TB以内，那么可以按 1 TB 的用户数据存储空间来规划集群实例的计算组数量。


**实例选型示例：**

如果有 5 TB 的原始数据，针对高性能分析场景，并有100并发以上的查询，建议采用8个4x4C SSD计算组规格，总计11.24 TB用户数据存储空间。

**说明：** [产品定价](https://www.aliyun.com/price/product#/gpdb/detail)中已经提供了一些常用计算组集群规格组合速查表。对于超过控制台自助创建页面的计算组数量，您可以通过提交工单或联系销售代表申请创建。

